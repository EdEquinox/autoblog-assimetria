# ðŸ¤– Guia de ConfiguraÃ§Ã£o Hugging Face

## 1ï¸âƒ£ Criar Conta no Hugging Face

1. Ir para https://huggingface.co
2. Clicar em **"Sign Up"**
3. Preencher:
   - Email
   - Username
   - Password
   - Aceitar termos
4. Confirmar email
5. Pronto! Conta criada âœ…

## 2ï¸âƒ£ Gerar Token de API

1. Ir para https://huggingface.co/settings/tokens
2. Clicar em **"New token"**
3. Preencher:
   - **Name**: `blog-ai` (ou qualquer nome)
   - **Type**: `read` (Ã© suficiente para gerar artigos)
   - **Role**: `User`
4. Clicar **"Generate token"**
5. **Copiar o token** (comeÃ§a com `hf_`)

âš ï¸ **Guarde bem!** O token sÃ³ aparece uma vez. Se perder, gere um novo.

## 3ï¸âƒ£ Adicionar Token ao Projeto

### OpÃ§Ã£o A: Arquivo `.env` (Desenvolvimento Local)

1. Abrir `backend/.env`:

```env
PORT=3001
NODE_ENV=development

DB_HOST=localhost
DB_PORT=5432
DB_NAME=blog
DB_USER=user
DB_PASSWORD=password

# Cole o token aqui â¬‡ï¸
HUGGINGFACE_API_KEY=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

2. Salvar e reiniciar o backend

### OpÃ§Ã£o B: Docker Compose (Com Docker)

1. Abrir `.env` na raiz do projeto:

```env
DB_HOST=postgres
DB_PORT=5432
DB_NAME=blog
DB_USER=user
DB_PASSWORD=password

# Cole o token aqui â¬‡ï¸
HUGGINGFACE_API_KEY=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

2. Reiniciar containers:

```bash
docker-compose down
docker-compose up --build
```

## 4ï¸âƒ£ Verificar se Funcionou

### Via API HTTP

```bash
curl -X POST http://localhost:3001/api/articles/generate \
  -H "Content-Type: application/json" \
  -d '{"topic": "Docker", "style": "informative"}'
```

### Esperado: Resposta JSON com artigo gerado âœ…

```json
{
  "id": "1",
  "title": "Docker: Guia Completo",
  "description": "Docker Ã© uma plataforma...",
  "content": "ConteÃºdo completo do artigo...",
  "tags": ["docker", "educaÃ§Ã£o", "tutorial"],
  "status": "published",
  "views": 0,
  "createdAt": "2024-01-15T10:30:00Z",
  "updatedAt": "2024-01-15T10:30:00Z"
}
```

### Se receber erro:

```json
{
  "error": "HUGGINGFACE_API_KEY not configured"
}
```

ðŸ‘‰ Verifique se o token foi adicionado corretamente ao `.env`

## 5ï¸âƒ£ Modelos DisponÃ­veis

O backend usa **Mistral-7B-Instruct-v0.2** por padrÃ£o (mais recente e confiÃ¡vel).

| Modelo | Velocidade | Qualidade | Status |
|--------|-----------|-----------|--------|
| **Mistral-7B-Instruct-v0.2** | RÃ¡pido âš¡ | Excelente â­â­â­â­ | âœ… Recomendado |
| HuggingFaceH4/zephyr-7b-beta | RÃ¡pido âš¡ | Excelente â­â­â­â­ | âœ… Funciona |
| meta-llama/Llama-2-7B-chat | MÃ©dio âš™ï¸ | Boa â­â­â­ | âœ… Funciona |
| google/flan-t5-large | RÃ¡pido âš¡ | MÃ©dia â­â­ | âœ… Alternativa |
| mistralai/Mistral-7B-Instruct-v0.1 | âŒ | âŒ | âŒ Descontinuado (erro 410) |

### Se receber erro 410 (Model not found):

O modelo foi removido da Hugging Face. Tente um dos modelos acima.

**Para trocar modelo:**

1. Editar `backend/src/services/aiClient.js`:

```javascript
// Linha ~27, mudar:
const modelUrl = 'https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta';
```

2. Reiniciar backend:
```bash
docker-compose restart backend
```

### Verificar Modelos DisponÃ­veis:

Ir para: https://huggingface.co/models?pipeline_tag=text-generation&sort=trending

E procurar por modelos com badge "Inference API" ðŸŸ¢

## 6ï¸âƒ£ Limites e Quotas

### Free Tier (Gratuito)
- âœ… Sem limite de requisiÃ§Ãµes
- âœ… Sem cartÃ£o de crÃ©dito
- âš ï¸ Modelos podem estar lentos durante picos
- âš ï¸ Prioridade baixa na fila

### Taxa de RequisiÃ§Ãµes
- ~30 requisiÃ§Ãµes por minuto
- Se exceder, aguarde 1 minuto e tente novamente

### Como Aumentar Limite?
1. Ir para https://huggingface.co/settings/billing/overview
2. Selecionar plano pago (opcional)
3. Usar crÃ©ditos para acesso prioritÃ¡rio

## 7ï¸âƒ£ Troubleshooting

### âŒ Erro: "AI generation failed, using fallback: Hugging Face API error: Request failed with status code 410"

**Causa:** Modelo foi removido ou descontinuado da Hugging Face

**SoluÃ§Ã£o:**

1. Usar modelo mais recente (v0.2):
```bash
# Editar backend/src/services/aiClient.js linha ~27
const modelUrl = 'https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2';
```

2. Ou usar modelo alternativo:
```javascript
const modelUrl = 'https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta';
```

3. Reiniciar:
```bash
docker-compose restart backend
```

4. Testar:
```bash
curl -X POST http://localhost:3001/api/articles/generate \
  -H "Content-Type: application/json" \
  -d '{"topic": "Python"}'
```

**Fallback:** Se falhar mesmo assim, o sistema usa gerador local automaticamente âœ…

### âŒ Erro: "HUGGINGFACE_API_KEY not configured"

**SoluÃ§Ã£o:**
```bash
# 1. Verificar se .env existe
cat backend/.env

# 2. Se nÃ£o existe, criar:
echo "HUGGINGFACE_API_KEY=hf_seu_token" >> backend/.env

# 3. Reiniciar backend
docker-compose restart backend
```

### âŒ Erro: "Invalid API token - please check your HUGGINGFACE_API_KEY"

**Causa:** Token invÃ¡lido ou expirado

**SoluÃ§Ã£o:**
1. Regenerar token em https://huggingface.co/settings/tokens
2. Atualizar `.env`
3. Reiniciar backend

### âŒ Erro: "Rate limit exceeded"

**Causa:** Muitas requisiÃ§Ãµes em pouco tempo

**SoluÃ§Ã£o:**
- Aguarde 1-2 minutos
- Tente novamente
- Fallback local Ã© usado automaticamente

### âŒ Erro: "Model no longer available"

**Causa:** Modelo descontinuado

**SoluÃ§Ã£o:**
- Ver seÃ§Ã£o "Modelos DisponÃ­veis"
- Trocar para modelo ativo (v0.2)

### âœ… Teste RÃ¡pido de Conectividade

```bash
# Verificar se token Ã© vÃ¡lido
curl -H "Authorization: Bearer $HUGGINGFACE_API_KEY" \
  https://huggingface.co/api/whoami

# Esperado: informaÃ§Ãµes do seu perfil
```

## 8ï¸âƒ£ Verificar Quotas

1. Ir para https://huggingface.co/settings/billing/overview
2. Ver uso do mÃªs
3. Ver limite restante

## 9ï¸âƒ£ Usar com Docker em ProduÃ§Ã£o

### `.env.production`

```env
DB_HOST=postgres
DB_PORT=5432
DB_NAME=blog
DB_USER=prod_user
DB_PASSWORD=super_secret_password

HUGGINGFACE_API_KEY=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
NODE_ENV=production
```

### Deploy:

```bash
docker-compose -f docker-compose.prod.yml up -d
```

## ðŸ”Ÿ Alternativas se Hugging Face Falhar

Se o token nÃ£o funcionar ou atingir limite:

1. **Fallback Local** (automÃ¡tico)
   - Gera artigos com templates
   - Sempre funciona
   - Sem qualidade de IA, mas suficiente

2. **JSONPlaceholder** (para testes)
   - Editar `aiClient.js` para usar essa funÃ§Ã£o
   - Mock data realista

3. **Outras APIs de IA:**
   - OpenAI (pago)
   - Anthropic Claude (pago)
   - Local LLM (Ollama, etc.)

## ðŸŽ¯ Resumo RÃ¡pido

```bash
# 1. Copiar token de https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=hf_...

# 2. Adicionar ao backend/.env
echo "HUGGINGFACE_API_KEY=hf_..." >> backend/.env

# 3. Reiniciar
docker-compose restart backend

# 4. Testar
curl http://localhost:3001/api/articles/generate

# âœ… Pronto!
```

## ðŸ’¡ Dicas

- âœ… Guarde o token em lugar seguro
- âœ… Nunca commitar `.env` no Git (usar `.env.example`)
- âœ… Regenere token se publicar cÃ³digo acidentalmente
- âœ… Monitore uso em https://huggingface.co/settings/billing/overview
- âœ… Use fallback como backup
- âœ… Teste com tÃ³picos diferentes para validar qualidade

## ðŸ“ž Suporte

Se tiver problemas:
1. Ver logs: `docker-compose logs backend`
2. Verificar token em https://huggingface.co/settings/tokens
3. Tentar regenerar token
4. Consultar https://huggingface.co/docs/api-inference

---

**Pronto para gerar artigos com IA!** ðŸš€
